# Ultimate Tic-Tac-Toe å¼·åŒ–å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ æ¦‚è¦

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã« **4ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘è¿½åŠ ** ã—ã¦Stable Baselines 3ã«ã‚ˆã‚‹å¼·åŒ–å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸï¼š

- `env_registration.py` - Gymnasiumç’°å¢ƒç™»éŒ²
- `config.yaml` - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š  
- `train_rl.py` - å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- `evaluate_rl.py` - è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### 1. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆï¼ˆæ¨å¥¨ï¼‰
python3 -m venv venv
source venv/bin/activate

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install "stable-baselines3[extra]>=2.3" "gymnasium[all]>=1.0" pyyaml torch
```

### 2. å‹•ä½œç¢ºèª

ç’°å¢ƒãŒæ­£ã—ãç™»éŒ²ã•ã‚Œã‚‹ã‹ãƒ†ã‚¹ãƒˆï¼š

```bash
python3 -c "import env_registration; import gymnasium as gym; env = gym.make('UTTTRLSim-v0'); print('Environment registered successfully!'); print(f'Observation space: {env.observation_space}'); print(f'Action space: {env.action_space}')"
```

## ğŸ¯ ä½¿ç”¨æ–¹æ³•

### å­¦ç¿’ã®å®Ÿè¡Œ

```bash
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å­¦ç¿’é–‹å§‹
python3 train_rl.py

# TensorBoardã§ãƒ­ã‚°ç›£è¦–ï¼ˆåˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ï¼‰
tensorboard --logdir logs/tb
```

### å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡

```bash
# 100ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã§è©•ä¾¡
python3 evaluate_rl.py

# ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ã‚’æŒ‡å®š
python3 evaluate_rl.py --episodes 50

# æç”»ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ
python3 evaluate_rl.py --render --episodes 5
```

## âš™ï¸ è¨­å®šã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

`config.yaml` ã‚’ç·¨é›†ã—ã¦å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ï¼š

```yaml
env_id: UTTTRLSim-v0
n_envs: 16          # ä¸¦åˆ—ç’°å¢ƒæ•°ï¼ˆCPUã‚³ã‚¢æ•°ã«å¿œã˜ã¦èª¿æ•´ï¼‰
total_steps: 2000000 # å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—æ•°
seed: 42

ppo_params:
  learning_rate: 0.0003
  batch_size: 4096    # ãƒãƒƒãƒã‚µã‚¤ã‚º
  n_steps: 2048
  # ãã®ä»–PPOãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿...
```

## ğŸ“Š æœŸå¾…ã•ã‚Œã‚‹çµæœ

### å­¦ç¿’é€²è¡Œä¾‹
```
Creating 8 environments...
Using Metal Performance Shaders (MPS) backend  # Apple Silicon
Creating PPO model...
Starting training for 1000000 steps...
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 45.2     |
|    ep_rew_mean     | 0.125    |
| time/              |          |
|    fps             | 2847     |
|    iterations      | 100      |
|    time_elapsed    | 72       |
|    total_timesteps | 204800   |
...
```

### è©•ä¾¡çµæœä¾‹
```
=== Evaluation Results ===
Episodes: 100
Mean reward: 0.65 Â± 0.32
ğŸ‰ Agent is performing well! (mostly winning)
```

## ğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

**Q. `ModuleNotFoundError: No module named 'utttrlsim'`**
```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰å®Ÿè¡Œã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
python3 train_rl.py
```

**Q. Apple Silicon Macã§ã€ŒMPS backend not availableã€**
```bash
# PyTorchã‚’æœ€æ–°ç‰ˆã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
pip install --upgrade torch
```

**Q. å­¦ç¿’ãŒé…ã„**
- `config.yaml`ã®`n_envs`ã‚’å¢—ã‚„ã™ï¼ˆCPUã‚³ã‚¢æ•°ã¾ã§ï¼‰
- `batch_size`ã¨`n_steps`ã‚’èª¿æ•´
- GPUãŒä½¿ãˆã‚‹å ´åˆã¯è‡ªå‹•ã§ä½¿ç”¨ã•ã‚Œã¾ã™

**Q. ä»–ã®RLãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ç§»è¡Œã—ãŸã„**
- `env_registration.py`ã¯ãã®ã¾ã¾ä½¿ç”¨å¯èƒ½
- TorchRLã€RLlibç­‰ã§ã‚‚åŒã˜`gym.make("UTTTRLSim-v0")`ãŒä½¿ãˆã¾ã™

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
your-project/
â”œâ”€â”€ src/utttrlsim/          # æ—¢å­˜ã®ç’°å¢ƒå®Ÿè£…
â”‚   â”œâ”€â”€ env.py              # â† UltimateTicTacToeEnv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ env_registration.py     # â† æ–°è¦è¿½åŠ 
â”œâ”€â”€ config.yaml            # â† æ–°è¦è¿½åŠ   
â”œâ”€â”€ train_rl.py            # â† æ–°è¦è¿½åŠ 
â”œâ”€â”€ evaluate_rl.py         # â† æ–°è¦è¿½åŠ 
â”œâ”€â”€ models/                # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰
â””â”€â”€ logs/                  # TensorBoardãƒ­ã‚°ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰
```

## ğŸ”§ é«˜åº¦ãªä½¿ç”¨æ³•

### åˆ†æ•£å­¦ç¿’
```bash
# ç’°å¢ƒæ•°ã‚’å¤§å¹…ã«å¢—ã‚„ã™
sed -i 's/n_envs: 8/n_envs: 32/' config.yaml
python3 train_rl.py
```

### ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
`train_rl.py`ã®`CheckpointCallback`éƒ¨åˆ†ã‚’æ‹¡å¼µã—ã¦ç‹¬è‡ªã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¿½åŠ å¯èƒ½ã€‚

### ä»–ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
PPOã‚’A2Cã€SACç­‰ã«å¤‰æ›´ã‚‚ç°¡å˜ï¼š
```python
from stable_baselines3 import A2C
model = A2C("MlpPolicy", vec_env, ...)
```

---

ã“ã‚Œã§**æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã«ä¸€åˆ‡æ‰‹ã‚’åŠ ãˆã‚‹ã“ã¨ãªã**ã€å¼·åŒ–å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒå®Œæˆã§ã™ï¼ğŸ‰